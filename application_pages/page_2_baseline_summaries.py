
import streamlit as st
import pandas as pd
from utils import generate_llm_summary


def main():
    st.markdown(
        "### Story: Baseline LLM Summaries - Establishing Initial Performance")
    st.markdown(
        """
        Before we can quantify risks and biases, we must first establish a **baseline** of the LLM's performance. 
        As a **Risk Manager**, you need to observe how the LLM, with its default prompt, summarizes the financial documents. 
        This baseline will serve as our reference point against which all subsequent assessments (factual accuracy, contradictions, sentiment bias, etc.) are measured.
        """
    )
    st.markdown(
        """
        We will now generate LLM summaries for all loaded financial documents using a standard, neutral prompt. 
        The LLM will also provide a confidence score for each generated summary, indicating its self-assessed certainty in the output.
        """
    )

    if 'data' not in st.session_state or not st.session_state.data:
        st.warning("Please load data in the 'Welcome & Setup' page first.")
        return

    st.markdown("### How this page helps you (Baseline LLM Summaries)")
    st.markdown(
        """
        This step is crucial for establishing a consistent foundation for all subsequent risk assessments. 
        By generating baseline summaries now, you ensure that every test and evaluation (from factual accuracy to adversarial testing) 
        is conducted on the same initial LLM output. This consistency is essential for meaningful comparative analysis 
        and for tracking improvements when you later refine prompts or implement mitigations. 
        As a Risk Manager, this baseline allows you to quantify initial risk levels and measure the effectiveness of interventions.
        """
    )

    st.subheader("1. Generate Baseline Summaries")
    # Initialize baseline_prompt_input in session_state if not present
    if 'baseline_prompt_input' not in st.session_state:
        st.session_state.baseline_prompt_input = "Summarize the following financial document concisely: \n\n{document_text}"

    baseline_prompt = st.text_area(
        "Baseline Prompt Template",
        value=st.session_state.baseline_prompt_input,
        height=100,
        key="baseline_prompt_input"
    )

    if st.button("Generate Baseline LLM Summaries", key="generate_baseline_btn"):
        with st.spinner("Generating baseline LLM summaries..."):
            for doc_id, doc_data in st.session_state.data.items():
                llm_output = generate_llm_summary(
                    doc_data['text'], baseline_prompt)
                st.session_state.data[doc_id]['llm_summary_baseline'] = llm_output['llm_summary']
                st.session_state.data[doc_id]['llm_confidence_baseline'] = llm_output['confidence_score']
            st.success("Baseline summaries generated successfully!")

    # Show results if baseline summaries exist
    if st.session_state.data and all('llm_summary_baseline' in d for d in st.session_state.data.values()):
        st.markdown("### Baseline Summary Results")
        st.markdown(
            """
            Below are the baseline summaries generated by the LLM for each document. 
            As a Risk Manager, reviewing these summaries allows you to get an initial sense of the LLM's summarization style, 
            tone, and content selection before diving into detailed risk assessments. 
            Compare these summaries with the ground truth to start identifying potential areas of concern.
            """
        )
        # Display summaries
        selected_doc_id = st.selectbox("Select a document to review its baseline summary:", options=list(
            st.session_state.data.keys()), key="baseline_doc_selector")
        if selected_doc_id:
            doc_data = st.session_state.data[selected_doc_id]
            st.subheader(
                f"Document: {selected_doc_id} - {doc_data['company']}")
            with st.expander("Original Document Text"):
                st.write(doc_data['text'])
            st.markdown(
                f"**Ground Truth Summary:**\n{doc_data['ground_truth_summary']}")
            st.markdown(
                f"**LLM Summary (Baseline):**\n{doc_data.get('llm_summary_baseline', 'N/A')}")
            st.markdown(
                f"**LLM Confidence Score (Baseline):** {doc_data.get('llm_confidence_baseline', 0.0):.2f}")

        st.markdown("---")
        if st.button("Next: Go to Factual Accuracy Assessment", key="next_page_2", type="primary"):
            st.session_state.current_step = 2
            st.rerun()
